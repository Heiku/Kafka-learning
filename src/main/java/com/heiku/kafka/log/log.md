
### 日志存储

![](/img/topic_partition_replication_log.png)

#### Log LogSegment

__在不考虑多副本的情况下__，一个分区对应一个日志（Log）。为了防止 Log 多大，切便于消息的维护和清理，将 Log 分成多个 LogSegment。  
在物理的上，Log 对应一个文件夹，而 LogSegment 对应于磁盘上的一个日志文件和两个索引文件。

每个 LogSegment 都有一个 __基准偏移量 baseOffset__，用来表示当前 LogSegment 中第一条消息的 offset，日志文件和索引文件都是根据
基准偏移量（baseOffset）命名的。

向 Log 中追加消息时是顺序写入的，只有最后一个 LogSegment(Active Segment) 才能执行写入操作，在之前所有的 LogSegment 都不能写入数据。

##### 日志索引

* .index

偏移量索引文件用来建立消息偏移量（offset）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置。

* .timeindex

时间戳索引文件根据指定的时间戳（timestamp）来查找对应的偏移量

Kafka 中的索引文件以 __稀疏索引（sparse index）__ 的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引值，
而是当写入一定量的消息（log.index.interval.bytes 4096B）时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项。

__稀疏索引__ 通过 __MappedByteBuffer__ 将索引文件映射到内存中，以加快索引的查询速度。偏移量索引文件中的偏移量是单调递增的，
查询指定偏移量时，使用 __二分查找__ 来快速定位偏移量的位置。稀疏索引的方式是磁盘空间、内存空间、查找时间等多方面之间的一个折中。

###### 偏移量索引

偏移量文件由多个偏移量索引构成，每个索引项占用 8 个字节

1. relativeOffset: 相对偏移量，表示消息相对于 baseOffset 的偏移量，占用 4 个字节 （文件名为baseOffset）
2. position: 物理地址，也就是消息在日志分段文件中对应的物理位置，占用 4 个字节 

```
relativeOffset  4B       relativeOffset = offset - baseOffset
position        4B
```

###### 时间戳索引

1. timestamp: 当前日志分段最大的时间戳
2. relativeOffset: 时间戳所对应的消息的相对偏移量

```
timestamp: 8B
relativeOffset: 4B
```

查找过程: timestamp -> relativeOffset -> position -> .log RecordBatch

#### 消息压缩

Kafka 实现的压缩方式是将多条消息一起进行压缩，保证了较好的压缩效果。在一般情况下，生产者发送的压缩数据在 broker 中也是保持压缩
状态进行存储的，消费者从服务端互殴去的也是压缩的消息，只有在消费者处理之前才会解压消息，这样保持了端对端的压缩。

#### 消息格式

![](/img/record-batch.png)

v2 版本将多个消息（Record） 打包存放到单个 RecordBatch 中，又通过 Varints 编码极大地节省了空间。



### 日志清理

Kafka 提供了两种日志清理策略：

(1) 日志删除（Log Retention）: 按照一定的保留策略直接删除不符合条件的日志分段
(2) 日志压缩（Log Compaction）: 针对每个消息的 key 进行整合，对于有相同的 key 的不同 value 值，只保留最后一个版本

#### 日志删除

Kafka 日志管理器会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件

1. 基于时间的保留策略

检查当前日志文件中是否有保留时间超过设定的阈值（retentionMs）来寻找可删除的日志分段文件集合（deletableSegments）

判断的狮虎采用日志分段的最大时间戳 largestTimeStamp 来计算，当要删除日志分段时，首先会从 Log 对象中所维护日志分段的跳跃表 （
ConcurrentSkipList） 中移除待删除的日志分段，以保证没有线程对这些日志分段进行读取操作。然后将日志分段所对应的所有文件加上 
".deleted" 的后缀，最后通过 "delete-file" 的延迟任务执行删除.

2. 基于日志大小

rententionSize 

3. 基于日志起始偏移量

基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量 baseOffset 是否小于等于 logStartOffset，
若是，则可以删除此日志分段。

#### 日志压缩

Log Compaction 对于有相同 key 的不用 value 值，只保留最后一个版本。可以想象当 Kafka 异常崩溃，在恢复时不需要读取 Kafka 中的
所有数据，而是只会读取最新的值。


### 磁盘存储

Kafka 依赖与文件系统（磁盘）来存储和缓存消息。在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，
并且不允许修改已写入的消息，__顺序写盘__

#### 页缓存

页缓存吧磁盘中的数据缓存到内存中，把对磁盘的访问变成对内存的访问。

* 具体过程

当一个进程准备读取磁盘上的文件内容是，操作系统会先查看待读取的数据所在的页（page）是否在页缓存（pageCache）中，如果存在，
则直接返回数据，从而避免对物理磁盘的 I/O 操作；如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，
之后再将数据返回进程。

如果一个进程需要将数据写入磁盘，那么操作系统会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，
最后将数据写入对应的页，而被修改过胡的页也就变成了 __脏页__，操作系统会在合适的时间把脏页中的数据写入磁盘，以保证数据的一致性。

#### 零拷贝

零拷贝（Zeri-Copy）是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。大大提高了应用程序的性能，减少了内核
和用户模式之间的上下文切换。

```
linux: sendfile()
Java: FileChannel.transferTo() 进行了包装
```

![](/img/zero-copy.png)

* 将本地文件发送的情况：

1. 调用 read()时，文件 A 中的内容被复制到内核模式下的 Read Buffer 中
2. CPU 控制将内核模式数据复制到用户模式下
3. 调用 write()时，将用户模式下的内容复制到内核模式下的 Socket Buffer 中
4. 将内核模式下的 Socket Buffer 的数据复制到网卡设备中传送

![](/img/zero-copy1.png)

零拷贝技术通过 DMA（Direct Memory Access）技术将文件内容复制到内核模式下的 Read Buffer 中。不过没有数据被复制 Socket Buffer，
相反只有包含数据的位置和长度的信息的 __文件描述符__ 加到 Socket Buffer 中。DMA 引擎直接将数据从内核模式中传递到网卡设备。  

这里数据只经历了 2 次复制就从磁盘中传送出去了，并且上下文切换也变成了 2 次。零拷贝是针对内核模式而言的，数据在内核模式下实现了
零拷贝。
